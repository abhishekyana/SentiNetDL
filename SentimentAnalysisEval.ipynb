{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetEmbeddings(path='./student_code/supportfiles/GloVe300.d'):\n",
    "    GloVe = pickle.load(open(path,'rb'))\n",
    "    W2ID = {w:i for i,w in enumerate(sorted(list(GloVe.keys())))}\n",
    "    EMB = torch.nn.Embedding(len(W2ID),300)\n",
    "    EMB.weight.requires_grad=False\n",
    "    GloVeW = np.vstack([GloVe[w] for w in W2ID])\n",
    "    EMB.weight.data.copy_(torch.from_numpy(GloVeW))\n",
    "    return W2ID, EMB\n",
    "W2ID,EMB = GetEmbeddings('./SupFiles/GloVe300.d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterit(s,W2ID):\n",
    "    s=s.lower()\n",
    "    S=''\n",
    "    for c in s:\n",
    "        if c in ' abcdefghijklmnopqrstuvwxyz0123456789':\n",
    "        \tS+=c\n",
    "    S = \" \".join([x  if x and x in W2ID else \"<unk>\" for x in S.split()])\n",
    "    return S\n",
    "\n",
    "\n",
    "def Sentence2Embeddings(sentence,W2ID,EMB):\n",
    "    if type(sentence)==str:\n",
    "        sentence = filterit(sentence, W2ID)\n",
    "        #print(sentence)\n",
    "        IDS = torch.tensor([W2ID[i] for i in sentence.split(\" \")])\n",
    "        return EMB(IDS)\n",
    "    if type(sentence)==list:\n",
    "        sembs = []\n",
    "        for sent in sentence:\n",
    "            sent = filterit(sent,W2ID)\n",
    "            IDS = torch.tensor([W2ID[i] for i in sent.split(\" \")])\n",
    "            sembs.append(EMB(IDS))\n",
    "        sembs = torch.nn.utils.rnn.pad_sequence(sembs,batch_first=True)\n",
    "        return sembs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SentimentA(torch.nn.Module):\n",
    "    def __init__(self,nE=300,nH=512,nL=2):\n",
    "        super().__init__()\n",
    "        self.rnn = torch.nn.LSTM(nE,nH,nL,batch_first=True)\n",
    "        self.fc = torch.nn.Linear(nH,1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "    def forward(self,X,*kwargs):\n",
    "        outs,(h,c) = self.rnn(X,*kwargs)\n",
    "        out = self.fc(h[-1,:,:])#(outs[:,-1,:])\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentA(\n",
       "  (rnn): LSTM(300, 512, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SA = SentimentA()\n",
    "SA.load_state_dict(torch.load('./SentimentAnalysisModel',map_location='cpu'))\n",
    "if torch.cuda.is_available(): SA = SA.cuda()\n",
    "SA.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9650],\n",
      "        [ 0.9996],\n",
      "        [-0.9832],\n",
      "        [ 0.8660],\n",
      "        [-0.9999]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sent = ['Hello all the movie is really bad', \n",
    "        'the movie is not bad at all',\n",
    "       'the movie is not good at all',\n",
    "       'the movie is not good but not bad too',\n",
    "       'I am really saddened by his demise']\n",
    "emb = Sentence2Embeddings(sent,W2ID,EMB)\n",
    "if torch.cuda.is_available(): emb=emb.cuda()\n",
    "print(2*(SA(emb)-0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Senti(sent):\n",
    "    emb = Sentence2Embeddings(sent,W2ID,EMB)\n",
    "    if torch.cuda.is_available(): emb=emb.cuda()\n",
    "    return 2*(SA(emb)-0.5).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.96499544],\n",
       "       [ 0.99962556],\n",
       "       [-0.98324347],\n",
       "       [ 0.86596274],\n",
       "       [-0.9999136 ]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Senti(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
